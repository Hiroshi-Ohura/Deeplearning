{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer.links as L\n",
    "import chainer.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import Variable\n",
    "from chainer.optimizers import SGD\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.training import StandardUpdater\n",
    "from chainer.training import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learningドリル - アクティベーション関数編 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででみなさんはchainerをある程度扱えるようになってきたと思います。いよいよ、Deep Learningにおける個別の様々な性質について学びます。これから学ぶことは基本的にchainerには依存しないことですので、Tensorflowなど別のDeep Learningフレームワークを使う場合でも役に立つはずです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax関数の性質"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはsoftmax関数について学びましょう。softmax関数は今まで何度も使ってきましたね。\n",
    "softmax関数の性質について、覚えて頂きたいことが3つあります。\n",
    "初めに列挙します。\n",
    "\n",
    "\n",
    "1. 出力値は$[0, 1]$の範囲に収まり、各次元の和を計算すると$1$になる\n",
    "2. ベクトルの各要素に定数を加算してもsoftmaxの結果は変わらない($\\forall b \\in R, x_i \\in R, \\mathrm{softmax}(x_1, x_2, \\ldots, x_n) = \\mathrm{softmax}(x_1+b, x_2+b, \\ldots, x_n+b)$)\n",
    "3. Softmaxの出力が2次元のとき、Sigmoid関数と一致する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力値は$[0, 1]$の範囲に収まり、各次元の和を計算すると$1$になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは簡単ですね。softmaxの式は入力の各次元を指数乗した上で、全体の和で割っています。割る数は割られる数より必ず大きくなりますので、結果は$1$以下となります。また、softmaxは各次元の和が$1$になるように定義されています。この性質により、 __softmax関数の出力はカテゴリカル変数に対する確率分布である__ と解釈することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、当然ですが1次元ベクトルを入力すると出力は必ず1になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.random(1).astype(np.float32).reshape((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31071031]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(Variable(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトルの各要素に定数を加算しても、softmaxの結果は変わらない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは試しに実験してみましょう。各要素の値がちょうど1ずつ違うベクトルを2つ用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.random.random(5).astype(np.float32).reshape((1,5))\n",
    "x2 = x1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "くっつけます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.r_[x1, x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80031389,  0.57449448,  0.76997077,  0.9507612 ,  0.75278902],\n",
       "       [ 1.80031395,  1.57449448,  1.76997077,  1.9507612 ,  1.75278902]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1行目と2行目でちょうど1ずつ違いますね。これをsoftmax関数にかけてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 0.20475373,  0.16336526,  0.19863418,  0.23799632,  0.19525044],\n",
       "          [ 0.20475374,  0.16336526,  0.19863418,  0.23799632,  0.19525044]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(Variable(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果がほぼ同じになりましたね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmaxの出力が2次元のとき、Sigmoid関数と一致する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これもやってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.random(2).astype(np.float32).reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44673532,  0.52645624]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはxに対するsoftmaxを計算しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 0.48008034,  0.51991969]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(Variable(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、sigmoidで同じ結果を得るには以下のように計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([ 0.51991969])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (x - x[0, 0])[0, 1:]\n",
    "F.sigmoid(Variable(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07972091], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2次元目が同じになりましたね。この2つの式に対するlossの値は一致します。正解ラベルが0のときと1のとき両方どうなるか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([ 0.65408099])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax_cross_entropy(Variable(x), Variable(np.array([1], dtype=np.int32)), normalize=False, reduce=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([ 0.65408099])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid_cross_entropy(Variable(z), Variable(np.array([1], dtype=np.int32)), normalize=False, reduce=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([ 0.7338019])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax_cross_entropy(Variable(x), Variable(np.array([0], dtype=np.int32)), normalize=False, reduce=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([ 0.7338019])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid_cross_entropy(Variable(z), Variable(np.array([0], dtype=np.int32)), normalize=False, reduce=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(np.array([1], dtype=np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにsoftmaxの出力が2次元のとき、完全に同一なネットワークをsigmoidを使って構成することができます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
